\section{基于最佳质量运输理论的匹配算法}

最优传输理论起源于两百多年前，由Monge提出的经典问题——确定以最小运输成本将一堆沙子从这个地方移动到另一个地方的最佳方式[9]。Kantorovich [31]证明了基于线性规划的最优运输计划的存在性
和唯一性。Monge-Kantorovich 优化已被用于从物理学、计量经济学到计算机科学的众多领域，包括数据压缩和图像处理[41]。最近十年，研究人员已经意识到，如果可以降低其高计算成本[16]、[54] ，
最优传输可以为图像处理提供强大的工具。. 但是，它有一个基本缺点，即变量的数量是（ķ2)，这对于计算机视觉和医学成像应用来说是不可接受的，因为高分辨率 3D 表面通常包含多达数十万个顶点。
另一种 Monge-Brenier 优化方案可以显着减少要优化的变量数量。在 1980 年代后期，Brenier [11]为一类特殊的最优运输问题开发了一种不同的方法，其中成本函数是二次距离。Brenier 的理论表明，
最优传输图是特殊凸函数的梯度图。假设目标域离散化为n样本，Monge-Brenier 的方法减少了未知变量（n2)到 o ( n )，大大降低了计算成本，提高了效率。

目前，最优传输理论之所以在计算机视觉领域开始发光发热，主要是因为该理论的计算机算法得到了极大的进展，求解一个OT问题不再是困难的问题。另一个方面是，最优传输理论主要研究的是两个分布之间
的最优传输映射，而图像在计算机科学界公认的一个流形分布定则的解释下，可以认为是嵌在高维图像空间下的概率分布，而两幅或多幅图像之间的匹配，其实就是计算两个分布之间的运输成本，换句话说即是
计算两个分布之间的最优传输映射，并根据映射函数的运算结果去分类。当然，这里有几个不可忽视的问题，一、经典的OT映射，需要两个分布之间的映射是质量守恒的，即运输过程中没有损失质量，用数学
语言描述映射是保测度的。二、经典的Wasserstein距离计算的是同一图像空间下的概率分布，如果是不同类的图像空间，该距离度量将会失效。三、尽管现如今有许多加速或简化OT映射计算的算法，但是速度较快的
如Sinkhon它计算的其实是一个正则化的简化版的伪OT映射，即它计算结果只能作为最优结果的近似。而OT映射的数值解法一部分是运算复杂度高，一部分是理论晦涩难懂算法实现困难。因此，研究人员一般会把
OT映射的计算按照特定的任务使用相应的定理，并采用一些如牛顿法、最速下降算法去求取推导出的一些公式，以此逼近OT映射。总而言之，OT映射计算算法的选择也是一个需要关注的问题。鉴于上述的各种
情况，目前，OT理论在视觉任务中的应用与发展一般分为四个方面：预处理、后处理、Wasserstein距离、解释GAN及相似模型并设计基于OT的匹配算法。

\subsection{Wasserstein距离}

假设$(M,g)$是一个黎曼流形，其黎曼度量为$g$。

\begin{definition}\label{def:wasserstein space}
    设$\mathcal{P}_p(M)$表示$M$上具有有限$pth$矩的所有概率测度$\mu$的空间，其中$p\ge 1$。假设存在某一点$x_0 \in M$，有$\int _{M} d(x,x_0)^P \mathrm{d}\mu(x) < + \infty$，其中$d$是$g$的测地距离。

    给定$\mathcal{P}_p$中的两个概率测度$\mu$ 和$\nu$，它们之间的Wasserstein距离被顶为最佳质量运输映射$T: M \to M$的运输成本，
    \begin{equation}\label{equation:wasserstein distance}
        W_p(\mu ,\nu ) := \inf _{T_\#\mu = \nu } \left( \int _M d(x,T(x))^p \mathrm{d}\mu (x) \right)^{\frac{1}{p}}. 
    \end{equation}
    下面的定理对当前的工作起着基础性作用。
\end{definition}
\begin{theorem}\label{theorem:Wassertein}
    Wasserstein距离$W_p$是Wasserstein空间$\mathcal{P}_p(M)$的黎曼度量，详细证明间参考文献[55]。
\end{theorem}

Wasserstein距离不仅给出了两个分布之间的距离，而且能够告诉我们它们具体如何不一样，即如何从一个分布转化为另一个分布，靠的就是联合分布 $(x,T(x))$。Wasserstein距离
之所以很难计算，一个重要原因是两个分布的维度一般成百上千，如果用传统的线性规划算法求解该问题，计算复杂度是难以承受的。这成为了一个限制其应用的难点目前能用显式计算
出来的只有两种情况一种是1维即$d=1,p=1$，另一种是高斯分布。当然，在精确解上有困难，我们可以考虑求一个近似解，其中利用计算几何中的工具，可以有效地解决最佳运输的具体
实例。例如，从连续到离散点状措施的运输成本可以通过多尺度算法计算\cite{merigot2011multiscale}，或通过欧几里得空间上的牛顿迭代[de Goes et al. 2012; Zhao et al. 2013]
最近这种基于牛顿法的计算方法被扩展到离散曲面[de Goes et, 2014].点云和线段之间的传输距离也在二维中基于平面的三角平铺和贪婪点到线段聚类来近似[de Goes ,2011]。另一项
工作提出了一个具有额外时间变量的最优运输的动态公式，对于距离成本的平方，Benamou和Brenier[2000]通过将一个分部在时间上平流到另一个分部的成本最小化来计算运输距离。对于
非平方距离代价，Solomon等人[2014a]将运输映射求解为向量场的流，其散度与输入密度的差值相匹配。

其他方法使用最优运输从多个密度聚集和平均信息。例如重心计算[Agueh和carlier 2011]，图上的密度传播[Solomon等人2014b]，以及“软”对应映射的计算[Solomon等人2012]。这些
问题通常通过一个多边际线性程序来解决[Agueh和carlier2011;Kim 和pass2013]，这对于大规模域是不可行的。一种变通的方法是使用带有亚梯度方向的L-BFGS来处理线性规划的对偶[Carlier等人2014]
但这种策略存在条件反射差和噪声结果的问题。

正则化为运输问题的近似求解提供了一种可能，长期以往，内点法一直使用障碍函数将线性规划转化为严格的凸问题，而熵正则化在最优运输的特殊情况下提供了[Cuturi 2013]中所述的几个关键
优势在熵正则化的情况下，使用迭代比例拟合(IPFP)或Sinkhorn-Knopp算法来解决最优运输问题[Deming and Stephan 1840; Sinkhorn 1976]，它可以在并行的GPU架构中实现，并用于计算
如上千个分布的重心[Cuturi 和Doucet 2014]。此外，有一部分工作[Convolution...]利用迭代标度方法解决熵正则化输运和相关问题的效率[Cu-turi 2013;Benamou等2015]。通过在连续语言中提出正则化传输，
并将这些算法的效率与曲面和图像等领域的离散化相结合，这种变化不仅仅是符号上的，而是带来了更快的迭代图像上的高斯核与表面的热核相连接；这些核可以在不预先计算成对距离矩阵的情况下进行计算。

\subsection{OT方法}

OT理论同样可以在图像匹配的前置处理和后置处理发挥作用。高精度点云配准任务[Accurate Point Cloud Registration with Robust Optimal Transport]，我们可以把这个复杂任务描述为两个问题：
(1) 如何寻找source和target的对应关系；
(2) 如何利用这个对应关系求解特定的变换。
对于(1)隐性地利用到了相似性的概念，直观来说就是特征匹配：用source的点去匹配target中的点，并计算他们的特征相似度。这里可以引入Entropic和unbalanced形式下的OT，文献中称为RobOT，并引入
Weighted RobOT Matching，具体是通过计算target set 在$\pi_ij$加权下的barycenter，得到加权的目标位置。到这里为止，我们简单的描述了如何利用RobOT 直接求解配准问题。
没有引入其他的regularization 项，但这种解决方案并不是完美的。如下例子目标是把彩色月亮匹配到蓝色月亮上去，我们简单的采用xyz作为每一个点的特征。虽然形状匹配的很好，但很明显它的拓扑结构乱了。
这是因为RobOT本身并没有regularize transformation, 这个在有较大rotation 的情况下非常明显。因为我们还加入了非deep learning based 前置预处理模块和后置finetune 模块。
这两个模块都是基于RobOT所以速度在毫秒级，并不影响整体的速度。总体而言，我们用了一个预处理模块（optimiatzion-based）， deep non-parametric 模块（支持多种deformation 
model，deep-learning based), 后处理模块（optimization-baed) 的三明治结构。我们称这个方法为 Deep-RobOT(D-RobOT)

至于为什么这么设计呢。三个模块对应三个原因
1）为什么加入预处理，一般而言大部分non-parametric模型都是针对与局部形变设计的regularization，需要预先移除全局translation，rotation, shear 和 scale。
2）为什么采用non-parametric， 局部形变的处理需要non-parametric 模型，另外通过任务类型可以选择相应的模型， 像场景流这类型小形变任务，control point based spline model 能求解平滑的流场，
对比full resolution 的位移场，spline 的结果一般更平滑， 另外control point 的引入可以大大降低计算内存消耗。
3）为什么采用 后处理， 这是因为不要过分的依赖深度模型，很多时候模型可能并不会给出完美的结果，这时候后处理可以修正模型误差。

除了上述例子之外，把OT方法用在匹配任务的前置或后置处理的例子还有很多。其中一个最为经典的例子便是\cite{ma2017robust}，利用OMT-Map实现一个区域保持映射，将源和目标映射到一个单位平面圆盘上，
而不会产生大面积失真。然后将表面配准问题转化为两个平面圆盘之间的地标匹配T-Map，使映射在整个域上具有一致的形象失真，同时使最大形象失真最小。

\subsection{OT匹配算法}

当前OT理论主要从两个方面启发图像匹配算法的设计，一是求取图像之间OT映射，二是OT理论在深度学习中的阐释。对于求取图像之间的OT映射，最为引人注意的便是医学图像上的配准以及3D点云的匹配。
如\cite{su2015optimal} 利用保角映射将具有圆盘拓扑的度量曲面映射到单位平面圆盘上，利用所产生的面积畸变获取其概率测度，通过计算具有两个概率测度的两个表面之间的唯一的最优质量运输映射
（用牛顿法进行能量优化）， 我们可以得到定义两个表面之间的Wasserstein距离的最优运输成本，这种Wasserstein距离可以在本质上测量基于曲面形状之间的差异，从而可以用于形状分类。再如\cite{RN1}
通过最小化两个域间联合分布的Wasserstein距离来解决上述挑战．提出一个定理将难以求解的Wasserstein距离原问题转化为一个简单的优化问题，并设计了一个联合Wasserstein自编码器模型（JWAE）
来求解该问题．然后，本文将JWAE成功应用在无监督图像翻译和跨域视频合成任务中，并生成高质量的图像和连贯的视频。

而对于OT理论在深度学习中的阐释，根据流形分布定则和流形嵌入定理[....]可以把数据集描述为数据流形，而对于图像数据集，它所表示的数据流形$\sum$嵌入在图像空间$\mathbb{R}^n$中。而数据集可以被抽象
成一个数据流形上的概率分布$\mu$，编码映射$\varphi_i : U_i \to \mathcal{Z}$将数据流形上的一个领域$U_i$映射到隐空间$\mathcal{Z}$上。换句话说深度学习中的编码映射和解码映射本质上是将陆行嵌入到
不同维数的欧氏空间中，如果流形的嵌入具有扭结结构，通过嵌入到不同维数的欧式空间可以解除扭结结构；如果初始流形嵌入的维数过高，通过改变嵌入空间而实现逐步降维，直至隐空间。那么这套说法解释了为什么
可以把图像描述成一个概率分布，即深度学习的学习对象。那么深度学习为什么可以得到能够描述这些流形分布的隐空间的呢？一种说法是万有逼近定理[Weierstrass]，即深度学习是复合简单函数来逼近任意的
连续函数和连续映射的基于如下定理
\begin{theorem}\label{theorem:Kolmogorov-Arnold}
    假设$f$是一个多元连续函数，那么$f$可以被写成单元连续函数的有限复合，
    \begin{equation*}\label{function:Kolmogorov-Arnold}
        f(x_1,x_2, \cdots, x_n) = \sum_{q=0}^{2n} \Phi _q \left ( \sum _{q=1}^n \phi_{p,q}(x_p)  \right ) 
    \end{equation*}
    这里$\phi , \Phi$分别称为内、外函数
\end{theorem}
我们有多种方式用深度神经网络来构造内、外函数，例如用Sigmoid、ReLU激活函数来表示内函数。由此可知，深度学习训练出隐空间的过程即编码过程其实是一个把原分布映射到隐空间的过程，然后再通过解码器映射到图像空间中，
这里研究人们把一些经典的深度学习模型如GAN model，使用OT的思想修改它的某个步骤，从而得到一些有效的图像匹配算法。

