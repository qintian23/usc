% !TeX root = ../translation.tex

\section{以前的工作}

\subsection{最优传输}

OT问题在各种领域中都起着重要的作用。有关详细的概述，我们可以参考读者的参考文献。[7]和[8]。

当输入域和输出域都是狄拉克质量时，OT问题可以作为一个标准的线性规划(LP)任务来处理。为了将这个问题扩展到一个大的数据集，Ref的作者。[9]在原来的LP问题中添加了一个熵正则化器；因此，用辛角算法可以快速计算正则化问题。所罗门等人[10]随后通过引入快速卷积，提高了计算效率。

求解OT问题的第二种方法是通过OT问题和凸几何之间的联系，通过最小化凸能量[6]来计算连续测度和点测度之间的OT映射。在参考文献中。[11]，作者然后通过勒让德对偶理论将凸几何观察的OT与坎托洛维奇对偶性联系起来。该方法是对该方法在高维空间上的推广。如果输入和输出都是连续密度，则求解OT问题等价于求解著名的蒙格-安培方程，这是一个高度非线性的椭圆型偏微分方程(PDE)。有了一个额外的虚拟时间维数，这个问题可以通过计算流体动力学[12–14]来放宽。

\subsection{生成模型}

在机器学习领域，能够生成复杂和高维数据的生成模型，最近正变得越来越重要和流行。具体来说，生成模型主要用于从给定的图像数据集中生成新的图像。一些方法，包括深度信念网络[15]和深度玻尔兹曼机器[16]已经在早期阶段被引入。然而，这些方法的训练通常是棘手的和低效的。后来，从变分AEs(VAEs)[17]的方案中取得了一个巨大的突破，其中解码器使用变分方法[17,18]从高斯分布中近似于真实的数据分布。最近遵循该方案的各种工作已经被提出，包括对抗性AEs(AAEs)[19]和瓦瑟斯坦AEs(WAEs)[20]。虽然vae的训练相对简单，但它们生成的图像看起来很模糊。在某种程度上，这是因为显式表示的密度函数可能不能表示真实数据分布的复杂性，而不能学习高维数据分布[21,22]。还提出了其他非危险性训练方法，包括PixelCNN[23]、PixelRNN[24]和WaveNet[25]。然而，由于其自回归性质，新样本的生成无法并行。

\subsection{对抗生成模型}

为了解决上述模型的缺点，提出了GANs[26]。尽管GANs是生成真实的样本的强大工具，但它们可能很难训练，并遭受模式崩溃。为了更好地进行GAN训练，人们提出了各种改进，包括改变损失函数(例如，WGAN[1])和通过裁剪[1]、梯度正则化[4,27]或光谱归一化[28]来正则化鉴别器为利普希茨。然而，gan的训练仍然很棘手，需要仔细的超参数选择。

\subsection{生成模型的评价}

生成模型的评估仍然具有挑战性。早期的工作包括概率标准[29]。然而，最近的生成模型(特别是GANs)不适合接受这样的评估。传统上，GANs的评估依赖于对少数例子或用户研究的视觉检查。最近，人们提出了若干定量评价标准。初始评分(IS)[30]同时衡量了多样性和图像质量。然而，它并不是一个距离度量标准。为了克服IS的缺点，在参考文献中引入了Frechet起始距离(FID)。[31].FID已被证明对图像损坏具有鲁棒性，并与视觉保真度很好地相关。在最近的一项工作[32]中，引入了分布的精度和查全率(PRD)来测量生成的数据分布和真实数据分布之间的精度和查全率。为了公平地比较GANs，我们在参考文献中进行了大规模的比较。[33]，在统一的网络架构下比较了7个不同的gan和vae，并建立了一个共同的评估基线。

\subsection{非对抗性方法}

最近也提出了各种非对抗性的方法。生成潜在优化(GLO)[34]采用了一种“无编码AE”方法，其中生成模型用非对抗损失函数训练，获得比VAE更好的结果。隐式极大似然估计(IMLE)[35]提出了一种与迭代最近点(ICP)相关的生成模型训练方法。后来，Hoshen和Malik[36]提出生成潜在的最近邻(GLANN)，结合GLO和GLANN的优势，其中嵌入从图像空间潜在空间首先发现使用GLO，然后任意分布和潜在之间的转换代码是使用IMLE计算。

其他方法利用具有可控雅可比矩阵[37–39]的DNNs直接逼近从噪声空间到图像空间的分布变换映射。最近，人们选择了基于能量的模型[40–42]，通过用[40–42]表示能量函数，通过吉布斯分布来模拟图像的分布。这些方法利用现有的模型交替生成假样本，然后利用生成的假样本和真实样本对模型参数进行优化。