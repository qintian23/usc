% !TeX root = ../translation.tex

\section{前期工作}

\subsection{最优传输}

OT问题在各种领域中都起着重要的作用。有关详细的概述，读者可以参照参考文献[7]和[8]。

当输入域和输出域都是Dirac质量时，OT问题可以作为一个标准的线性规划(LP)任务来处理。为了将这个问题扩展到大的数据集，参考文献[9]的作者在原来的LP问题中添加了一个熵正则化器，则用Sinkhorn算法可以快速计算正则化问题。后来Solomon等人[10]随后通过引入快速卷积，提高了计算效率。

求解OT问题的第二种方法是通过OT问题和凸几何之间的联系来最小化凸能量[6]，从而计算连续测度和逐点测度之间的OT映射。在参考文献[11]中，作者通过Legendre对偶理论将凸几何OT问题与Kantorovich对偶问题联系起来。本文所提出的方法是该方法在高维空间上的一种扩展。如果输入和输出都是连续密度，则求解OT问题等价于求解著名的Monge-Ampère方程，这是一个高度非线性的椭圆型偏微分方程(PDE)。有了一个额外的虚拟时间维数，这个问题可以通过计算流体动力学[12–14]来解决。

\subsection{生成模型}

在机器学习领域，能够生成复杂和高维数据的生成模型，最近正变得越来越重要。具体来说，生成模型主要用于从给定的图像数据集中生成新的图像。一些方法，包括深度信念网络[15]和深度玻尔兹曼机器[16]已经在早期阶段被引入。然而，这些方法的训练通常是棘手的和低效的。后来，从变分AE(VAE)[17]的方案中取得了一个巨大的突破，其中解码器使用变分方法[17,18]从Gaussian分布中逼近了真实的数据分布。最近遵循该方案的各种工作已经被提出，包括对偶自编码器（AAE）[19]和Wasserstein AE（WAE）[20]。虽然VAE的训练相对简单，但它们生成的图像看起来很模糊。在某种程度上，这是因为显式表示的密度函数可能无法表示真实数据分布的复杂性和无法学习高维数据分布[21,22]。后来，研究人员还逐步提出了其他非对抗性训练方法，包括PixelCNN[23]、PixelRNN[24]和WaveNet[25]。然而，由于这些方法的自回归性质，新样本的生成无法并行。

\subsection{对抗生成模型}

针对上述模型的缺点，提出了GAN[26]。尽管GAN是生成逼真样本的强大工具，但它们很难训练，并会出现模式崩溃。为了更好地进行GAN训练，人们提出了各种改进，包括改变损失函数(如WGAN[1])和通过剪切[1]、梯度正则化[4,27]或光谱归一化[28]来正则化判别器。然而，GAN的训练仍然很棘手，需要仔细的超参数选择。

\subsection{生成模型的评估}

生成模型的评估仍然具有挑战性。早期的工作包括概率标准[29]。然而，最近的生成模型(特别是GAN)不适合接受这样的评估。传统上，GAN的评估依赖于对少数例子或用户研究的视觉检查。近年来，人们提出了若干定量评价标准。Inception score(IS)[30]同时衡量了多样性和图像质量。然而，它并不是一个距离度量标准。为了克服IS的缺点，研究人员在参考文献中引入了Fréchet inception distance(FID)[31]。FID已被证明对图像损坏具有鲁棒性，并与视觉保真度很好地相关性。在最近的研究[32]中，引入了分布的精度和召回率(PRD)，这两个指标用于测量真实数据分布和生成数据分布之间的精度和查全率。为了公平地评测GAN，研究人员在参考文献[33]中进行了大规模比较，在统一的网络架构下，研究人员比较了7种不同的GAN和VAE，并建立了一个通用的评价标准。

\subsection{非对抗性方法}

最近研究人员也提出了各种非对抗性的方法。生成潜在优化(GLO)[34]采用了一种“无编码AE”方法，其中生成模型用非对抗损失函数训练，获得比VAE更好的结果。隐式极大似然估计(IMLE)[35]提出了一种与迭代最近点(ICP)相关的生成模型训练方法。后来，Hoshen和Malik[36]提出生成隐含最近邻(GLANN)，该方法结合GLO和GLANN的优势，该方法首先利用GLO发现了从图像空间到隐空间的嵌入，然后利用IMLE计算出了任意分布与隐藏代码之间的转换。


其他方法利用具有可控Jacobian矩阵的DNN直接逼近从噪声空间到图像空间的分布变换映射[37-39]。最近，人们选择了基于能量的模型[40–42]，通过用[40–42]表示能量函数，通过Gibb分布来模拟图像的分布。这些方法利用现有的模型交替生成假样本，然后利用生成的假样本和真实样本对模型参数进行优化。